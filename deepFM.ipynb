{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import math\n",
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# deepFM = FM + DNN\n",
    "n = 5 # number of samples\n",
    "d = m = 10 # number of features\n",
    "\n",
    "W = [0] * m # w_i -- scalar for each feature\n",
    "V = [[0] * m for i in range(m)] # V_i for each feature is interaction with others\n",
    "\n",
    "y = sigmoid(y_fm + y_dnn) # result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FM + SGD\n",
    "# https://www.csie.ntu.edu.tw/~b97053/paper/Factorization%20Machines%20with%20libFM.pdf\n",
    "\n",
    "# y_fm = np.inner(W, X)\n",
    "# for i in range(d):\n",
    "#     for j in range(i + 1, d):\n",
    "#         y_fm += np.inner(V[i], V[j]) * X[i] * X[j]\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))        \n",
    "\n",
    "def dsigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "        \n",
    "class FM(object):\n",
    "    # l = lamda = regularization paramets\n",
    "    # etha = learning rate\n",
    "    # sigma = initialization\n",
    "    # p = number of features\n",
    "    # n = number of samples\n",
    "    # k = the dimensionality of the factorization\n",
    "    # size(V) = p * k\n",
    "    def __init__(self, l=0.01, etha=0.01, sigma=0.001, k=5):\n",
    "        self.l = l\n",
    "        self.etha = etha\n",
    "        self.sigma = sigma\n",
    "        self.k = 0\n",
    "        self.w0 = 0\n",
    "        self.W = None\n",
    "        self.V = None\n",
    "    \n",
    "    def fit(self, X, Y, p, n_iter=20):\n",
    "        self.n = X.shape[0]\n",
    "        self.p = p\n",
    "        self.W = np.zeros(self.p)\n",
    "        self.V = self.sigma * np.random.randn(self.p, self.k)\n",
    "        \n",
    "        for iteration in range(n_iter):\n",
    "            for x, y in zip(X, Y):\n",
    "                pred = self.predict_sample(x)\n",
    "                # eq 19 + eq 5\n",
    "                dl_w0 = (sigmoid(pred * y) - 1) * y\n",
    "                self.w0 -= self.etha * (dl_w0 + 2 * self.l * self.w0)\n",
    "\n",
    "#                 for i in range(self.p):\n",
    "#                     if x[i] == 0:\n",
    "#                         continue\n",
    "                for i, fval in x:\n",
    "                    dl_wi = dl_w0 * fval\n",
    "                    self.W[i] -= self.etha * (dl_wi + 2 * self.l * self.W[i])\n",
    "    \n",
    "                    for f in range(self.k):\n",
    "                        v_sum = sum([x[j] * self.V[j, f] for j in range(p)]) - self.V[i, f] * fval\n",
    "                        dl_v = dl_wi * v_sum\n",
    "                        self.V[i, f] -= self.etha * (dl_v + 2 * self.l * self.V[i, f])        \n",
    "            \n",
    "        return self\n",
    "        \n",
    "    def predict_sample(self, x):\n",
    "        res = self.w0\n",
    "        for j, fval in x:\n",
    "            res += self.W[j] * fval\n",
    "        for f in range(self.k):\n",
    "            s1 = 0\n",
    "            s2 = 0\n",
    "            for j, fval in x:\n",
    "                s1 += self.V[j, f] * fval\n",
    "                s2 += (self.V[j, f] * fval) ** 2\n",
    "            res += 0.5 * (s1 ** 2 - s2)\n",
    "            \n",
    "        return res\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_sample(x) for x in X])\n",
    "    \n",
    "    def scale(self, Y):\n",
    "        return np.array([sigmoid(y) for y in Y])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# deep component\n",
    "# FFN\n",
    "# https://habr.com/post/198268/,/\n",
    "\n",
    "# for i in range(h):\n",
    "#     a = sigma(W * a + b)\n",
    "# y_dnn = W * a + b\n",
    "\n",
    "\n",
    "class DNN(object):\n",
    "    \n",
    "    def __init__(self, alpha=0.5, p=50):\n",
    "        self.alpha = alpha # Скорость обучения\n",
    "        self.p = p # Количество скрытых z нейронов\n",
    "        \n",
    "    def backpropagate(self, x_in, y):\n",
    "        t = [0] * self.m\n",
    "        t[y] = 1\n",
    "        \n",
    "        x = [0] * self.n\n",
    "        for i, fval in x_in:\n",
    "            x[i] = fval\n",
    "            \n",
    "        # step 4. скрытый нейрон z\n",
    "        z_in = [np.dot(self.V[:, i], x) + self.V0[i] for i in range(self.p)]\n",
    "        z = [sigmoid(a) for a in z_in]\n",
    "\n",
    "        # step 5. выходной нейрон y\n",
    "        y_in = [np.dot(self.W[:, i], z_in) + self.W0[i] for i in range(self.m)]\n",
    "        y = [sigmoid(a) for a in y_in]\n",
    "        \n",
    "        # backpropagation\n",
    "        # step 6. evaluate y error\n",
    "        sigma = np.array([(t[i] - y[i]) * dsigmoid(y_in[i]) for i in range(self.m)])\n",
    "        delta_W = np.array([[self.alpha * sigma[k] * z[j] for k in range(self.m)] for j in range(self.p)])\n",
    "        delta_W0 = self.alpha * sigma\n",
    "\n",
    "        # step 7. evaluate z error\n",
    "        sigma_in = [np.dot(sigma, self.W[j]) for j in range(self.p)]\n",
    "        sigma_j = np.array([sigma_in[j] * dsigmoid(z_in[j]) for j in range(self.p)])\n",
    "        delta_V = np.array([[self.alpha * sigma_j[j] * x[i] for j in range(self.p)] for i in range(self.n)])\n",
    "        delta_V0 = self.alpha * sigma_j\n",
    "\n",
    "        # Смещение скрытого нейрона j\n",
    "        self.V += delta_V\n",
    "        self.V0 += delta_V0\n",
    "        # Смещение нейрона на выходе\n",
    "        self.W += delta_W\n",
    "        self.W0 += delta_W0\n",
    "        \n",
    "        return mean_squared_error(t, y)\n",
    "\n",
    "    def fit(self, X, Y, n, m=2, n_iter=3):\n",
    "        self.n = n # количество признаков\n",
    "        self.m = m # количество выходных y нейронов\n",
    "        # Смещение скрытого нейрона j\n",
    "        self.V = np.random.random((self.n, self.p)) - 0.5\n",
    "        self.V0 = np.random.random(self.p) - 0.5\n",
    "        # Смещение нейрона на выходе\n",
    "        self.W = np.random.random((self.p, self.m)) - 0.5\n",
    "        self.W0 = np.random.random(self.m) - 0.5\n",
    "\n",
    "        for iteration in range(n_iter):\n",
    "            print(iteration)\n",
    "            error = 0\n",
    "            for x, y in zip(X, Y):\n",
    "                error += self.backpropagate(x, y)\n",
    "#             print(error / len(Y))\n",
    "        \n",
    "    def predict_sample(self, x_in):\n",
    "        x = [0] * self.n\n",
    "        for i, fval in x_in:\n",
    "            x[i] = fval\n",
    "        z_in = [np.dot(self.V[:, i], x) + self.V0[i] for i in range(self.p)]\n",
    "        y = [sigmoid(np.dot(self.W[:, i], z_in) + self.W0[i]) for i in range(self.m)]\n",
    "        \n",
    "        return y[1]\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_sample(x) for x in X])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DeepFM\n",
    "\n",
    "class DeepFM(object):\n",
    "    \n",
    "    def __init__(self, feature_count):\n",
    "        self.feature_count = feature_count\n",
    "        self.fm = FM()\n",
    "        self.dnn = DNN()\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        print('[fit] FM')\n",
    "        self.fm.fit(X, Y, self.feature_count)\n",
    "        print('[fit] DNN')\n",
    "        self.dnn.fit(X, Y, self.feature_count)\n",
    "        print('[fit] Done')\n",
    "        \n",
    "    def predict_sample(self, x):\n",
    "        y_fm = self.fm.predict_sample(x)\n",
    "        \n",
    "        y_dnn = self.dnn.predict_sample(x)\n",
    "        \n",
    "        return sigmoid(y_fm + y_dnn)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_sample(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95266455  0.95951973  0.87693838  0.82977878  0.92653548  0.96863567\n",
      "  0.94904921]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# dnn = DNN()\n",
    "# fm = FM()\n",
    "deepFM = DeepFM(5)\n",
    "X_train = np.array([[(2, 2), (3, 0), (4, 1), (0, 2)],\n",
    "                   [(1, 1), (2, 2), (3, 1), (4, 1), (0, 2)],\n",
    "                   [(1, 1), (2, 1), (3, 2), (4, 0), (0, 2)],\n",
    "                   [(1, 1), (2, 1), (3, 0), (4, 0), (0, 2)],\n",
    "                   [(1, 0), (2, 2), (3, 1), (4, 1)],\n",
    "                   [(1, 0), (2, 2), (3, 2), (4, 1), (0, 2)],\n",
    "                   [(1, 0), (2, 2), (3, 1), (0, 2)]])\n",
    "Y_train = np.array([1, 1, 0, 0, 1, 1, 1])\n",
    "# fm.fit(X_train, Y_train)\n",
    "# dnn.fit(X_train, Y_train)\n",
    "deepFM.fit(X_train, Y_train)\n",
    "\n",
    "print(deepFM.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '10000174058809263569', 'click': '0.5'}\n"
     ]
    }
   ],
   "source": [
    "# read data (avazu dataset)\n",
    "# https://www.kaggle.com/c/avazu-ctr-prediction/data\n",
    "# train ?\n",
    "# test 4,5 млн сэмплов\n",
    "sample_path = 'dataset/sampleSubmission.gz'\n",
    "train_path = 'dataset/train.gz'\n",
    "test_path = 'dataset/test.gz'\n",
    "\n",
    "with gzip.open(sample_path, 'rt') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "features:\n",
    "numerical = maybe log\n",
    "categorical = one-hot\n",
    "text = hashing trick = hash function mod (10^6 + 1) -> categorical\n",
    "\n",
    "click 0/1\n",
    "\n",
    "app_category     text\n",
    "app_domain       text\n",
    "app_id           text\n",
    "device_id        text\n",
    "device_ip        text\n",
    "device_model     text\n",
    "site_category    text\n",
    "site_domain      text\n",
    "site_id          text\n",
    "C1,14-21         categorical\n",
    "device_type      categorical\n",
    "device_conn_type categorical\n",
    "banner_pos       numerical\n",
    "hour             numerical\n",
    "id               numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "numerical_features = ['banner_pos', 'hour', 'id']\n",
    "categorical_features = ['device_type', 'device_conn_type']\n",
    "text_features = ['app_category', 'app_domain', 'app_id', \n",
    "                 'device_id', 'device_ip', 'device_model', \n",
    "                 'site_category', 'site_domain', 'site_id']\n",
    "\n",
    "def prepare_sample(sample):\n",
    "    global feature_to_index, index_to_feature\n",
    "    \n",
    "    result = []\n",
    "    click = int(sample.get('click', -1))\n",
    "    for fname, fvalue in sample.items():\n",
    "        if fname in numerical_features:\n",
    "            fvalue = math.log(int(fvalue) + 1)\n",
    "        elif fname in text_features:\n",
    "            fname = \"{}_{}\".format(fname, abs(hash(fvalue)) % (10 ** 4))\n",
    "            fvalue = 1\n",
    "        else:\n",
    "            fname = \"{}_{}\".format(fname, fvalue)\n",
    "            fvalue = 1\n",
    "        if feature_to_index.get(fname, False):\n",
    "            result.append((feature_to_index[fname], fvalue))\n",
    "        \n",
    "    return (result, click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34795\n"
     ]
    }
   ],
   "source": [
    "# get features\n",
    "feature_to_index = dict()\n",
    "index_to_feature = dict()\n",
    "with open('dataset/features', 'r') as in_file:\n",
    "    for feature in in_file:\n",
    "        num = len(feature_to_index)\n",
    "        feature_to_index[feature.strip()] = num\n",
    "        index_to_feature[num] = feature.strip()\n",
    "print(len(feature_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save features\n",
    "with open('dataset/features', 'w') as out:\n",
    "    for x, y in features_count.items():\n",
    "        print(x, file=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "train_path = 'dataset/train.gz'\n",
    "\n",
    "train_dataset = []\n",
    "with gzip.open(train_path, 'rt') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    for num, row in enumerate(reader):\n",
    "        if num % 1000000 == 0:\n",
    "            print(num)\n",
    "        if num == 100:\n",
    "            break\n",
    "        sample = prepare_sample(row)\n",
    "        train_dataset.append(sample)\n",
    "#         print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# learning model\n",
    "features_count = len(feature_to_index)\n",
    "deepFM = DeepFM(features_count)\n",
    "X_train, Y_train = zip(*train_dataset)\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "deepFM.fit(X_train, Y_train)\n",
    "\n",
    "print(deepFM.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = 'dataset/test.gz'\n",
    "\n",
    "test_dataset = []\n",
    "with gzip.open(test_path, 'rt') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    for num, row in enumerate(reader):\n",
    "        if num % 1000000 == 0:\n",
    "            print(num)\n",
    "        if num == 100:\n",
    "            break\n",
    "        sample = prepare_sample(row)\n",
    "        test_dataset.append(sample)\n",
    "#         print(sample)\n",
    "X_test, Y_test = zip(*train_dataset)\n",
    "deepFM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
